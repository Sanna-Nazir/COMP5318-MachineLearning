{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"group4_best_algorithm1.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ArSXO3y8qPJI","colab_type":"text"},"source":["Importing Required Libraries"]},{"cell_type":"code","metadata":{"id":"gpOzO_g5oLAn","colab_type":"code","colab":{}},"source":["from pandas import read_csv\n","import numpy as np\n","from numpy import mean, absolute\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TKQuhtHgqS50","colab_type":"text"},"source":["Loading Dataset"]},{"cell_type":"code","metadata":{"id":"2Aiphl7Hog-Y","colab_type":"code","colab":{}},"source":["# loading the dataset\n","data = read_csv(\"./forestfires.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NUMu21rQqUz9","colab_type":"text"},"source":["Encoding Months and Days"]},{"cell_type":"code","metadata":{"id":"bH8U2FPNomgH","colab_type":"code","colab":{}},"source":["encode_months = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, \n","                 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, \n","                 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n","encode_days = {'mon': 1, 'tue': 2, 'wed': 3, 'thu': 4, \n","               'fri': 5, 'sat': 6, 'sun': 7 }\n","data = data.replace({'month': encode_months, 'day': encode_days});"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_AvcdbE0qXmj","colab_type":"text"},"source":["Split data into input (X) and output (Y) variables"]},{"cell_type":"code","metadata":{"id":"VVynOAsloo8f","colab_type":"code","colab":{}},"source":["X = data.iloc[:,0:12]\n","Y = data.iloc[:,12].values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vBI0hDQwqfxJ","colab_type":"text"},"source":["Standardizing the Data"]},{"cell_type":"code","metadata":{"id":"01xzQ-LForoo","colab_type":"code","colab":{}},"source":["def standardData(z, mean, std): \n","    z_standard = (z - mean)/ std\n","    return z_standard\n","\n","X = standardData(X,X.mean(),X.std())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cRb8P1r0qs9Q","colab_type":"text"},"source":["Feature Extraction using PCA"]},{"cell_type":"code","metadata":{"id":"cZnoZcmPouWC","colab_type":"code","colab":{}},"source":["#Retaining 95% of data post PCA.\n","def enable_pca(X):\n","  pca = PCA(.95)\n","  pca.fit(X)\n","  X_pca = pca.transform(X)\n","  print(\"PCA run succesfully. %.2f Features extracted.\" % X_pca.shape[1])\n","  return X_pca"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SnBryPgPqrkq","colab_type":"text"},"source":["Splitting data into Training and Testing sets"]},{"cell_type":"code","metadata":{"id":"cuh6xwZ7oxaf","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,shuffle=False )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U52DvW0Hqyni","colab_type":"text"},"source":["Function for calculating Negative Log Likelihood"]},{"cell_type":"code","metadata":{"id":"-B-7bR0Uoz0V","colab_type":"code","colab":{}},"source":["def NLL(Y,Y_pred):\n","  n=Y.shape[0]\n","  variance = np.var(Y_pred, ddof=1)\n","  first_term= (n/2)*np.log(2*np.pi*variance)\n","  second_term=0\n","  for i in range(n):\n","    second_term+= (Y[i]-Y_pred[i])**2 \n","  second_term=second_term/(2*variance)\n","  NLL = first_term+second_term\n","  return NLL"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"opvAvQOtq2Y2","colab_type":"text"},"source":["Function for implementing optimised AdaBoost Regressor"]},{"cell_type":"code","metadata":{"id":"vKTSTT59o3JM","colab_type":"code","colab":{}},"source":["def AdaBoost(nest,lo,lr):\n","  AdB = AdaBoostRegressor(random_state=0, n_estimators=nest, loss=lo, learning_rate=lr)\n","  AdB.fit(X_train, y_train)\n","  y_pred = AdB.predict(X_test)\n","  print(\"AdaBoost Regression\")\n","  return y_pred"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VanSIOQCq7GW","colab_type":"text"},"source":["Function for running PCA and AdaBoost on the Dataset and printing the result metrics"]},{"cell_type":"code","metadata":{"id":"JtMhN7sBo6hs","colab_type":"code","outputId":"676444f3-962a-40a2-9472-1fe62342a64d","executionInfo":{"status":"ok","timestamp":1573212481380,"user_tz":-660,"elapsed":1777,"user":{"displayName":"anshu kumar","photoUrl":"","userId":"01489329396941591981"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["X= enable_pca(X)\n","y_pred = AdaBoost(100,'square',1)\n","\n","print(\"Root Mean Square Error is:\" , np.sqrt(mse(y_test,y_pred)))\n","print(\"Mean Absolute Error is:\" , mae(y_test,y_pred))\n","print(\"Mean Absolute Deviation is:\" ,mean(absolute(y_pred - mean(y_pred))))\n","print(\"Negative Log Likelihood is: \",NLL(y_test,y_pred))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["PCA run succesfully. 10.00 Features extracted.\n","AdaBoost Regression\n","Root Mean Square Error is: 65.16242022177141\n","Mean Absolute Error is: 21.908538235243984\n","Mean Absolute Deviation is: 9.6334939909227\n","Negative Log Likelihood is:  2272.719994552467\n"],"name":"stdout"}]}]}